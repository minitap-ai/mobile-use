// Here is the default config that will be used if no override is provided.
{
  "default": {
    "planner": {
      "provider": "openai",
      "model": "gpt-5-nano",
      "fallback": {
        "provider": "openai",
        "model": "gpt-5-mini"
      }
    },
    "orchestrator": {
      "provider": "openai",
      "model": "gpt-5-nano",
      "fallback": {
        "provider": "openai",
        "model": "gpt-5-mini"
      }
    },
    "cortex": {
      "provider": "openai",
      "model": "gpt-5",
      "fallback": {
        "provider": "openai",
        "model": "o4-mini"
      }
    },
    "screen_analyzer": {
      // Needs vision!
      "provider": "openai",
      "model": "gpt-4o",
      "fallback": {
        "provider": "openai",
        "model": "gpt-5-mini" // or a vision-capable equivalent
      }
    },
    "executor": {
      "provider": "openai",
      "model": "gpt-5-nano",
      "fallback": {
        "provider": "openai",
        "model": "gpt-5-mini"
      }
    },
    "utils": {
      "hopper": {
        // Needs at least a 256k context window.
        "provider": "openai",
        "model": "gpt-5-nano",
        "fallback": {
          "provider": "openai",
          "model": "gpt-5-mini"
        }
      },
      "outputter": {
        "provider": "openai",
        "model": "gpt-5-nano",
        "fallback": {
          "provider": "openai",
          "model": "gpt-5-mini"
        }
      }
    }
  },
  // This is the config we recommend.
  // To use it, copy it to llm.override.jsonc, following llm.override.template.jsonc.
  "recommended": {
    "planner": {
      "provider": "minitap",
      "model": "meta-llama/llama-4-scout",
      "fallback": {
        "provider": "minitap",
        "model": "meta-llama/llama-4-maverick"
      }
    },
    "orchestrator": {
      "provider": "minitap",
      "model": "openai/gpt-oss-120b",
      "fallback": {
        "provider": "minitap",
        "model": "meta-llama/llama-4-maverick"
      }
    },
    "cortex": {
      "provider": "minitap",
      "model": "google/gemini-2.5-pro",
      "fallback": {
        "provider": "minitap",
        "model": "openai/gpt-5"
      }
    },
    "screen_analyzer": {
      "provider": "minitap",
      "model": "meta-llama/llama-3.2-90b-vision-instruct",
      "fallback": {
        "provider": "minitap",
        "model": "openai/gpt-4o"
      }
    },
    "executor": {
      "provider": "minitap",
      "model": "meta-llama/llama-3.1-70b-instruct",
      "fallback": {
        "provider": "minitap",
        "model": "openai/gpt-5-mini"
      }
    },
    "utils": {
      "hopper": {
        // Needs at least a 256k context window.
        "provider": "minitap",
        "model": "openai/gpt-5-nano",
        "fallback": {
          "provider": "minitap",
          "model": "openai/gpt-5-mini"
        }
      },
      "outputter": {
        "provider": "minitap",
        "model": "openai/gpt-5-nano",
        "fallback": {
          "provider": "minitap",
          "model": "openai/gpt-5-mini"
        }
      }
    }
  }
}
