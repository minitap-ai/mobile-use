// Here is the default config that will be used if no override is provided.
{
  "default": {
    "planner": {
      "provider": "openai",
      "model": "gpt-5-mini"
    },
    "orchestrator": {
      "provider": "openai",
      "model": "gpt-5-mini"
    },
    "contextor": {
      "provider": "openai",
      "model": "gpt-5-mini"
    },
    "cortex": {
      "provider": "openai",
      "model": "o4-mini"
    },
    "executor": {
      "provider": "openai",
      "model": "gpt-5-nano"
    }
  },
  // This is the config we recommend.
  // To use it, copy it to llm.override.jsonc, following llm.override.template.jsonc.
  "recommended": {
    "planner": {
      "provider": "openrouter",
      "model": "meta-llama/llama-4-scout"
    },
    "orchestrator": {
      "provider": "openrouter",
      "model": "meta-llama/llama-4-scout"
    },
    "contextor": {
      "provider": "openai",
      "model": "gpt-5-mini"
    },
    "cortex": {
      "provider": "google",
      "model": "gemini-2.5-pro"
    },
    "executor": {
      "provider": "openai",
      "model": "gpt-5-nano"
    }
  }
}
